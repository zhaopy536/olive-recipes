keywords:
    aitk
arch: llama3
recipes:
    - file: "llama3_2_qnn_config.json"
      device: npu
      ep: QNNExecutionProvider
      aitk:
        oliveFile: "../microsoft-Phi-3.5-mini-instruct/QNN/config.json"
    - file: "llama3_2_vitis_ai_config.json"
      device: npu
      ep: VitisAIExecutionProvider
      aitk:
        oliveFile: "VitisAI/Llama-3.2-1B-Instruct_quark_vitisai_llm.json"
        requirementsPatches:
          - AutoGptq
        runtimeOverwrite:
          executeEp: CUDAExecutionProvider
        evalRuntime: AMDNPU
    - file: "llama3_2_ov_config.json"
      devices:
        - npu
      ep: OpenVINOExecutionProvider
    - file: "llama3_2_ov_gpu_config.json"
      devices:
        - cpu
        - gpu
      ep: OpenVINOExecutionProvider
    - file: "llama3_2_trtrtx_config.json"
      device: gpu
      ep: NvTensorRTRTXExecutionProvider
      aitk:
        oliveFile: "NvTensorRtRtx/Llama-3.2-1B-Instruct_model_builder_fp16.json"
    - file: "llama3_2_dml_config.json"
      device: gpu
      ep: DmlExecutionProvider
    - file: "llama3_2_migraphx_config.json"
      device: gpu
      ep: MIGraphXExecutionProvider
aitk:
    modelInfo:
        id: "huggingface/meta-llama/Llama-3.2-1B-Instruct"
        version: 4
        p0: true
